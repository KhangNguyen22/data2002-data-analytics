---
title: "490503902_Assignment"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(ggplot2)
library(skimr)
library(visdat)
```
# Executive summary
* Item 1
What are we analysing?

* Item 2

# Data Cleaning key points


```{r importing, message=FALSE, tidy=TRUE}
# CITATION The following 100 line cleaning code is mostly based on the following work and is only slightly modified for the use of this report.
# Author: Garth Tarr
# Date: 10/09/2020
# Title: Survey data cleaning
# Code Version: 1
# Type: Rmarkdown
# Availability: "https://pages.github.sydney.edu.au/DATA2002/2020/assignment/survey_cleaning.html#"


raw = read_csv("class_survey.csv")
# changes all spaces into underscores and lowercases the whole string for column names
clean_df = raw %>% janitor::clean_names()

## Remove people who automatically submitted without doing survey. Reduce from 174 rows to 172 rows
clean_df <- clean_df[rowSums(is.na(clean_df))<20,]

# Shorten the names of specific columns
colnames(clean_df) = stringr::str_replace(string = colnames(clean_df),
                                   pattern = "what_is_your_",
                                   replacement = ""
                                   )
colnames(clean_df) = stringr::str_replace(string = colnames(clean_df),
                                   pattern = "on_average_how_many_hours_per_week_did_you_",
                                   replacement = ""
                                   )
colnames(clean_df)[2] = "covid_tests"
colnames(clean_df)[4] = "postcode"
colnames(clean_df)[5] = "dentist"
colnames(clean_df)[6] = "university_work"
colnames(clean_df)[7] = "social_media"
colnames(clean_df)[8] = "dog_or_cat"
colnames(clean_df)[9] = "live_with_parents"
colnames(clean_df)[10] = "exercising"
colnames(clean_df)[12] = "asthma"
colnames(clean_df)[13] = "paid_work"
colnames(clean_df)[14] = "fav_season"
colnames(clean_df)[16] = "height"
colnames(clean_df)[17] = "floss_frequency"
colnames(clean_df)[18] = "glasses"
colnames(clean_df)[20] = "steak_preference"
colnames(clean_df)[21] = "stress_level"
## Change postcode to character
clean_df = clean_df %>% mutate(
  postcode = as.character(postcode)
)
## Change all height to cm
clean_df = clean_df %>% dplyr::mutate(
  height = dplyr::case_when(
    height < 2.3 ~ height*100,
    TRUE ~ height
  )
)

## Group gender into 3 categories 

clean_df = clean_df %>% mutate(
  gender = toupper(gender),
  gender = stringr::str_sub(gender, start = 1, end = 1),
  gender = case_when(
    gender == "F" ~ "Female",
    gender == "M" ~ "Male",
    gender == "N" ~ "Non-binary"
  )
)
steak_levels = c("Rare", "Medium-rare", "Medium", 
                 "Medium-well done", "Well done", 
      
                            "I don't eat beef")
clean_df = clean_df %>% 
  mutate(
    steak_preference = factor(steak_preference, levels = steak_levels)
  )
# Change timestamp to POSIXct for easier handling
clean_df$timestamp <-  lubridate::dmy_hms(clean_df$timestamp)

# Create 2 other dataframes based on clean_df ready for hypothesis testing
df_postcode <- clean_df[is.na(clean_df$postcode)==FALSE,]
df_exercising <- clean_df[is.na(clean_df$exercising)==FALSE,]
glimpse(clean_df)
```


* **Imported class_survey.csv** into R and cleaned the data by shortening the column names and renamed columns. This improves readibility as well as conciseness. 
* **Removed 2 survey observations** where survey was submitted without any input because these observations are useless and do not add any new information to the survey data. 
* **Converted postcode into character** data type as postcode is a categorical variable. I changed all height into cm, grouped gender into 3 categories (male,female and non-binary) and gave an order to steak preferences output.  

* Further, I changed the timestamp variable from character data type to POSIXct data type for easier handling of date time object. 

* After cleaning, there are 3 main data frames used in this report.
  1. **clean_df** = This data frame contains **172 rows** of observations, containing all the observations that have a covid tests value. This data frame will be used in **section 2.4**
  2. **df_postcode** = This data frame is based on the clean_df and contains only **156 rows** of observations due to the removal of NA values in the postcode variable. This dataframe will be used in **section 2.5**.
  3. **df_exercising** =  This data frame is based on the clean_df and contains only **166 rows** of observations due to the removal of NA values in the postcode variable. This dataframe will be used in **section 2.5**.

I only fully cleaned variables(postcode and exercising) for which I will use for our data analysis by removing null values and checking if the values of the variable made sense. 



## Is this a random sample of DATA2002 students?

To answer this question, we need to define what is a random sample. 

A  sample is a subset of population. A random sample is a sample where each person has an equal independent probability of being chosen from a population. 

Yes, this is a sample with only 174 people which is less than the total population, but is it  random?  The test data was collected  through a Google form survey via voluntary choice and was advertised on Edstem. This suggests that the sample is not random as survey participants were more likely to be studious students who read Edstem posts and so is not representative of the true population of DATA2002. Hence, **no**, this is not a random sample of DATA2002. To be random would require a random selection from a database of DATA2002 students that made it compulsory to do the survey.

## What are the potential biases? Which variables are most likely to be subjected to this bias?
**Potential biases**:

* **Selection bias**: Due to the sampling design through voluntary participation, this meant that only motivated students who read the Edstem post were selected to participate. A reduction in selection bias would not occur if a larger sample was taken through greater advertising.

* **Sensitive questions**: Some of the questions in the survey were sensitive questions, which prompted participants to fill in answers that are not objectively true. For example, the **height variable** would have the tendency for participants to increase their height due to the fear of appearing short. Another variable would be the **exercising variable** where participants may want to appear fitter by exaggerating how many hours they exercise. **Paid work** would have a bias of increased hours as participants may want to appear to be hard working. 

**Glasses** variable would have bias from


* **Recall Bias**: **Floss frequency** and **dentist** variable suffer from recall bias as participants may want to appear more



## Are there any questions that needed improvement to generate useful data?

Yes!
Shoe size is impossible to clean! Why?


## Does the number of COVID tests follow a Poisson distribution?
**Do a chi-square hypothesis test**

To test this question, we will use a chi-square...

$H_0:$ The number of COVID tests does not follow a Poisson distribution

$H_1:$ The number of COVID tests does follow a Poisson distribution

**Assumptions**:
**Need to apply filter**

**Decision**:


## Perform two other hypothesis tests. 
### Give some rationale for why you selected these hypothesis tests and interpret the results. Be sure to mention any limitations in the data that may impact your findings.

**Do a chi-square hypothesis test**

To test this question, we will use a chi-square...

$H_0:$ The number of COVID tests does not follow a Poisson distribution
$H_1:$ The number of COVID tests does follow a Poisson distribution

**Assumptions**:
**Need to apply filter**

**Decision**: