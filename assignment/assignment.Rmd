---
title: "490503902_Assignment"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(ggplot2)
library(skimr)
library(visdat)
```
# Executive summary
* Item 1
What are we analysing?

* Item 2

# Data Cleaning key points


```{r importing, message=FALSE, tidy=TRUE}
# CITATION The following 100 line cleaning code is mostly based on the following work and is only slightly modified for the use of this report.
# Author: Garth Tarr
# Date: 10/09/2020
# Title: Survey data cleaning
# Code Version: 1
# Type: Rmarkdown
# Availability: "https://pages.github.sydney.edu.au/DATA2002/2020/assignment/survey_cleaning.html#"


raw = read_csv("class_survey.csv")
# changes all spaces into underscores and lowercases the whole string for column names
clean_df = raw %>% janitor::clean_names()

## Remove people who automatically submitted without doing survey. Reduce from 174 rows to 172 rows
clean_df <- clean_df[rowSums(is.na(clean_df))<20,]

# Shorten the names of specific columns
colnames(clean_df) = stringr::str_replace(string = colnames(clean_df),
                                   pattern = "what_is_your_",
                                   replacement = ""
                                   )
colnames(clean_df) = stringr::str_replace(string = colnames(clean_df),
                                   pattern = "on_average_how_many_hours_per_week_did_you_",
                                   replacement = ""
                                   )
colnames(clean_df)[2] = "covid_tests"
colnames(clean_df)[4] = "postcode"
colnames(clean_df)[5] = "dentist"
colnames(clean_df)[6] = "university_work"
colnames(clean_df)[7] = "social_media"
colnames(clean_df)[8] = "dog_or_cat"
colnames(clean_df)[9] = "live_with_parents"
colnames(clean_df)[10] = "exercising"
colnames(clean_df)[12] = "asthma"
colnames(clean_df)[13] = "paid_work"
colnames(clean_df)[14] = "fav_season"
colnames(clean_df)[16] = "height"
colnames(clean_df)[17] = "floss_frequency"
colnames(clean_df)[18] = "glasses"
colnames(clean_df)[20] = "steak_preference"
colnames(clean_df)[21] = "stress_level"
## Change postcode to character
clean_df = clean_df %>% mutate(
  postcode = as.character(postcode)
)
## Change all height to cm
clean_df = clean_df %>% dplyr::mutate(
  height = dplyr::case_when(
    height < 2.3 ~ height*100,
    TRUE ~ height
  )
)

## Group gender into 3 categories 

clean_df = clean_df %>% mutate(
  gender = toupper(gender),
  gender = stringr::str_sub(gender, start = 1, end = 1),
  gender = case_when(
    gender == "F" ~ "Female",
    gender == "M" ~ "Male",
    gender == "N" ~ "Non-binary"
  )
)
steak_levels = c("Rare", "Medium-rare", "Medium", 
                 "Medium-well done", "Well done", 
      
                            "I don't eat beef")
clean_df = clean_df %>% 
  mutate(
    steak_preference = factor(steak_preference, levels = steak_levels)
  )
# Change timestamp to POSIXct for easier handling
clean_df$timestamp <-  lubridate::dmy_hms(clean_df$timestamp)

# Create 2 other dataframes based on clean_df ready for hypothesis testing
df_postcode <- clean_df[is.na(clean_df$postcode)==FALSE,]
df_exercising <- clean_df[is.na(clean_df$exercising)==FALSE,]
```


* **Imported class_survey.csv** into R and cleaned the data by shortening the column names and renamed columns. This improves readibility as well as conciseness. 
* **Removed 2 survey observations** where survey was submitted without any input because these observations are useless and do not add any new information to the survey data. 
* **Converted postcode into character** data type as postcode is a categorical variable. I changed all height into cm, grouped gender into 3 categories (male,female and non-binary) and gave an order to steak preferences output.  

* Further, I changed the timestamp variable from character data type to POSIXct data type for easier handling of date time object. 

* After cleaning, there are 3 main data frames used in this report.
  1. **clean_df** = This data frame contains **172 rows** of observations, containing all the observations that have a covid tests value. This data frame will be used in **section 2.4**
  2. **df_postcode** = This data frame is based on the clean_df and contains only **156 rows** of observations due to the removal of NA values in the postcode variable. This dataframe will be used in **section 2.5**.
  3. **df_exercising** =  This data frame is based on the clean_df and contains only **166 rows** of observations due to the removal of NA values in the postcode variable. This dataframe will be used in **section 2.5**.

I only fully cleaned variables(postcode and exercising) for which I will use for our data analysis by removing null values and checking if the values of the variable made sense. 



## Is this a random sample of DATA2002 students?

To answer this question, we need to define what is a random sample. A  sample is a subset of population chosen by a statistician. 

equal probability of being chosen. This is not the case as the survey is geared more towards studious students who regularly check Edstem posts. Further, since the 
 
 
Yes, this is a sample with only 174 people recorded in the survey but is it truly random? The way the test data collected was through voluntary choice and was advertised... This suggests it was not random for the

Also, to be a truly random sample of the DATA2002 population, the sample must be a true representation of all the types of people from the DATA2002 population.

We are not sure if the sample population is representative of the true population.


## What are the potential biases? Which variables are most likely to be subjected to this bias?


## Are there any questions that needed improvement to generate useful data?

Shoe size is impossible to clean! Why?


## Does the number of COVID tests follow a Poisson distribution?
**Do a chi-square hypothesis test**
To test this question, we will use a chi-square...

$H_0:$ The number of COVID tests does not follow a Poisson distribution
$H_1:$ The number of COVID tests does follow a Poisson distribution

**Assumptions**:
**Need to apply filter**

**Decision**:


## Perform two other hypothesis tests. Give some rationale for why you selected these hypothesis tests and interpret the results. Be sure to mention any limitations in the data that may impact your findings.

## Cleaning survey data

### Read in the data




